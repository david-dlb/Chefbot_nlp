{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7343bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import json\n",
    "import spacy as sp\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopword')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nlp = sp.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4acdeb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the Intents.....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>¿Cuál es tu receta favorita para cocinar?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>¿Cómo se hace una salsa de tomate casera?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>¿Qué plato prepararías para una cena romántica?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>¿Cuál es la diferencia entre freír y saltear?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>¿Cómo se hace un buen risotto?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1089</td>\n",
       "      <td>¿Qué opinas sobre el matrimonio entre personas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1090</td>\n",
       "      <td>¿Cuál es tu estilo de música favorito y por qué?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1091</td>\n",
       "      <td>¿Crees en la evolución?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1092</td>\n",
       "      <td>¿Cuál ha sido tu trabajo favorito y por qué?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1093</td>\n",
       "      <td>¿Qué opinas sobre la pena de cárcel?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1094 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  label\n",
       "0              0          ¿Cuál es tu receta favorita para cocinar?      1\n",
       "1              1          ¿Cómo se hace una salsa de tomate casera?      1\n",
       "2              2    ¿Qué plato prepararías para una cena romántica?      1\n",
       "3              3      ¿Cuál es la diferencia entre freír y saltear?      1\n",
       "4              4                     ¿Cómo se hace un buen risotto?      1\n",
       "...          ...                                                ...    ...\n",
       "1089        1089  ¿Qué opinas sobre el matrimonio entre personas...      0\n",
       "1090        1090   ¿Cuál es tu estilo de música favorito y por qué?      0\n",
       "1091        1091                            ¿Crees en la evolución?      0\n",
       "1092        1092       ¿Cuál ha sido tu trabajo favorito y por qué?      0\n",
       "1093        1093               ¿Qué opinas sobre la pena de cárcel?      0\n",
       "\n",
       "[1094 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/last-cook.csv\")\n",
    "df_cook = pd.read_csv(\"Data/intents_cook.csv\")\n",
    "df_cook_others = pd.read_csv('Data/intents_cook_others.csv')\n",
    "\n",
    "print(\"Processing the Intents.....\")\n",
    "with open('Data/intents.json') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "df_cook_others[\"label\"] = df_cook_others.label.map({ 'cook': 1, 'others': 0})\n",
    "df_cook[\"label\"] = df_cook.label.map({ 'name_to_prepare': 1, 'ingredient_to_name': 0})\n",
    "df_cook_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89cc0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text_lower = text.lower()\n",
    "    token_word = nltk.word_tokenize(text_lower, \"spanish\")\n",
    "    # algunos textos tienen caracteres raros al pricipio, por tanto se eliminan\n",
    "    token_word[0] = clear_first_token(token_word[0])\n",
    "    # stopwords\n",
    "    stopwords_esp = stopwords.words(\"spanish\")\n",
    "    i = 0\n",
    "    while i < len(token_word):\n",
    "        # se eliminan los tokens que se encuentren dentro de las stopwords\n",
    "        if token_word[i] in stopwords_esp:\n",
    "            token_word.remove(token_word[i])\n",
    "        # se elimina cualquier token que sea distinto de caracteres alfanumericos\n",
    "        elif not token_word[i].isalpha():\n",
    "            token_word.remove(token_word[i])\n",
    "        else:\n",
    "            # como nltk no lematiza textos en esp se usa spacy\n",
    "            word = nlp(token_word[i])[0]\n",
    "            token_word[i] = word.lemma\n",
    "            i = i + 1\n",
    "    return token_word\n",
    "\n",
    "def clear_first_token(token):\n",
    "    result = \"\"\n",
    "    char = '\\ufeff'\n",
    "    for i in range(len(token)):\n",
    "        if token[i] != char : result += token[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d97ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "\n",
    "# print('Precision score: ', format(precision_score(y_test, predictions)))\n",
    "# print('Recall score: ', format(recall_score(y_test, predictions)))\n",
    "# print('F1 score: ', format(f1_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20267c90",
   "metadata": {},
   "source": [
    "### clasificar si me estas hablando de cocina o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf3848f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo usando support vector machine y vectorizando con tfidf\n",
    "def cook_others(text):\n",
    "    # Dividir el conjunto de datos de entrenamiento y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_cook_others['text'], df_cook_others['label'], random_state=1)\n",
    "    \n",
    "    tfidf_vect = TfidfVectorizer()\n",
    "    tfidf_vect.fit(df_cook_others[\"text\"])\n",
    "    train_X_tfidf = tfidf_vect.transform(X_train)\n",
    "    text_data = tfidf_vect.transform([text])\n",
    "\n",
    "    svm = SVC(C=4.0, kernel='linear', degree=3, random_state=0, probability=True)\n",
    "    svm.fit(train_X_tfidf, y_train)\n",
    "    \n",
    "    \n",
    "    return svm.predict(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e529901",
   "metadata": {},
   "source": [
    "### clasificar que tipo de pregunta de cocina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d88c2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cook(text):\n",
    "    # Dividir el conjunto de datos de entrenamiento y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_cook['text'], df_cook['label'], random_state=1)\n",
    "    \n",
    "    count_vector = CountVectorizer()\n",
    "    \n",
    "    training_data = count_vector.fit_transform(X_train)\n",
    "    \n",
    "    testing_data = count_vector.transform(X_test)\n",
    "    text_data = count_vector.transform([text])\n",
    "\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(training_data, y_train)\n",
    "    \n",
    "    return naive_bayes.predict(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949f291b",
   "metadata": {},
   "source": [
    "### Clasificar en que tipo de pregunta varia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16358cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def others(text):\n",
    "    x = []\n",
    "    y_train = []\n",
    "    for i in range(4):\n",
    "    #     print(intents[\"intents\"][i])\n",
    "        label = intents[\"intents\"][i][\"tag\"]\n",
    "        for j in intents[\"intents\"][i][\"patterns\"]:\n",
    "            x.append(j)\n",
    "            y_train.append(label)\n",
    "            \n",
    "    # Instantiate the CountVectorizer method\n",
    "    count_vector = CountVectorizer()\n",
    "    # Fit the training data and then return the matrix\n",
    "    training_data = count_vector.fit_transform(x)\n",
    "    text_data = count_vector.transform([text])\n",
    "\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(training_data, y_train)\n",
    "    \n",
    "    return naive_bayes.predict(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d8ef39",
   "metadata": {},
   "source": [
    "### Modelos que devuelven la respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3951c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# devolver una respuesta de cocina segun el intent\n",
    "def search(text, first, second):\n",
    "    ma = -1000000\n",
    "    sol = \"\"\n",
    "    doc = nlp(text)\n",
    "    for i in range(df.shape[0]): \n",
    "        aux = nlp(str(df[first][i]))\n",
    "        value = doc.similarity(aux)\n",
    "        if (value > ma):\n",
    "            ma = value\n",
    "            sol = df[second][i]\n",
    "    return sol\n",
    "  \n",
    "# Devolver una respuesta varia aleatoria segun el intent\n",
    "def response_others(tag):\n",
    "    for i in range(4):\n",
    "    #     print(intents[\"intents\"][i])\n",
    "        label = intents[\"intents\"][i][\"tag\"]\n",
    "        if label == tag:\n",
    "            rand = int(random.uniform(0,len(intents[\"intents\"][i][\"responses\"])))\n",
    "            print(rand)\n",
    "            return intents[\"intents\"][i][\"responses\"][rand]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bcab2d",
   "metadata": {},
   "source": [
    "### Obtener la respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4385a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pepinos y zanahorias helados '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_response(text):\n",
    "    firstIntent = cook_others(text)[0]\n",
    "    if firstIntent == 0:\n",
    "        intentOthers = others(text)[0]\n",
    "        return response_others(intentOthers)\n",
    "    else:\n",
    "        cook_intents = cook(text) \n",
    "        if cook_intents == 0:\n",
    "            return search(text, \"ingredients\", \"title\")\n",
    "\n",
    "        if cook_intents == 1:\n",
    "            return search(text, \"title\", \"instructions\")\n",
    "    return firstIntent\n",
    "\n",
    "get_response(\"alguna receta que me sugieras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab3c9598846bb01a90bc4fb3fb70919349b21f3aac0df0f83a83137ce8a42a56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
