{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6215c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import json\n",
    "import spacy as sp\n",
    "\n",
    "nlp = sp.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b06b957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the Intents.....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Que hacer con 1 1/2 tazas de Oporto leonado, 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Quiero Tarta de queso de higos confitados, ave...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Como preparar Posole de pavo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Si tengo 1/4 de taza de yogur natural de leche...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Como preparar Tarta de nueces a la antigua usa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>6571</td>\n",
       "      <td>😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>6572</td>\n",
       "      <td>Muchos besos no puedo darlos pero si decirlo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>6573</td>\n",
       "      <td>Gracias mi amorrrr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>6574</td>\n",
       "      <td>Te quiero millones</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>6575</td>\n",
       "      <td>Yo también</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6576 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  label\n",
       "0              0  Que hacer con 1 1/2 tazas de Oporto leonado, 1...      1\n",
       "1              1  Quiero Tarta de queso de higos confitados, ave...      1\n",
       "2              2                      Como preparar Posole de pavo       1\n",
       "3              3  Si tengo 1/4 de taza de yogur natural de leche...      1\n",
       "4              4  Como preparar Tarta de nueces a la antigua usa...      1\n",
       "...          ...                                                ...    ...\n",
       "6571        6571   😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘😘...      0\n",
       "6572        6572       Muchos besos no puedo darlos pero si decirlo      0\n",
       "6573        6573                                 Gracias mi amorrrr      0\n",
       "6574        6574                                 Te quiero millones      0\n",
       "6575        6575                                         Yo también      0\n",
       "\n",
       "[6576 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"Data/train-esp.json\")\n",
    "df_cook = pd.read_csv(\"Data/intents_cook.csv\")\n",
    "df_cook_others = pd.read_csv('Data/intents_cook_others.csv')\n",
    "\n",
    "print(\"Processing the Intents.....\")\n",
    "with open('Data/intents.json') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "df_cook_others[\"label\"] = df_cook_others.label.map({ 'cook': 1, 'others': 0})\n",
    "df_cook[\"label\"] = df_cook.label.map({ 'title': 2, 'instructions': 1, 'title_instructions': 0})\n",
    "df_cook_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbd1a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/bin/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casa</th>\n",
       "      <th>como</th>\n",
       "      <th>dinero</th>\n",
       "      <th>estás</th>\n",
       "      <th>gana</th>\n",
       "      <th>hola</th>\n",
       "      <th>la</th>\n",
       "      <th>llámame</th>\n",
       "      <th>mañana</th>\n",
       "      <th>por</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   casa  como  dinero  estás  gana  hola  la  llámame  mañana  por\n",
       "0     0     1       0      1     0     1   0        0       0    0\n",
       "1     1     0       1      0     2     0   1        0       0    1\n",
       "2     0     0       0      0     0     0   0        1       0    0\n",
       "3     0     0       0      0     0     1   0        1       1    0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir los documentos\n",
    "documents = ['hola, como estás!',\n",
    "                'Gana dinero, gana por la casa.',\n",
    "                'Llámame.',\n",
    "                'Hola, Llámame mañana?']\n",
    "# Importar el contador de vectorizacion e inicializarlo\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "# Visualizar del objeto'count_vector' que es una instancia de 'CountVectorizer()'\n",
    "count_vector.fit(documents)\n",
    "names = count_vector.get_feature_names()\n",
    "\n",
    "doc_array = count_vector.transform(documents).toarray()\n",
    "doc_array\n",
    "\n",
    "frequency_matrix = pd.DataFrame(data=doc_array, columns=names)\n",
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df4bc0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 6576\n",
      "Number of rows in the training set: 4932\n",
      "Number of rows in the test set: 1644\n"
     ]
    }
   ],
   "source": [
    "# Dividir el conjunto de datos de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_cook_varios['text'], df_cook_varios['label'], random_state=1)\n",
    "print('Number of rows in the total set: {}'.format(df_cook_varios.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c943d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "349395a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd3245f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = naive_bayes.predict(testing_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f59f340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9884428223844283\n",
      "Precision score:  0.9938650306748467\n",
      "Recall score:  0.994475138121547\n",
      "F1 score:  0.9941699907947222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions)))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions)))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5c766552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cook_others(text):\n",
    "    # Dividir el conjunto de datos de entrenamiento y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_cook_others['text'], df_cook_others['label'], random_state=1)\n",
    "    \n",
    "    # Instantiate the CountVectorizer method\n",
    "    count_vector = CountVectorizer()\n",
    "    # Fit the training data and then return the matrix\n",
    "    training_data = count_vector.fit_transform(X_train)\n",
    "    # Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "    testing_data = count_vector.transform(X_test)\n",
    "    text_data = count_vector.transform([text])\n",
    "\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(training_data, y_train)\n",
    "    \n",
    "    return naive_bayes.predict(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "63eed934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cook(text):\n",
    "    # Dividir el conjunto de datos de entrenamiento y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_cook['text'], df_cook['label'], random_state=1)\n",
    "    \n",
    "    # Instantiate the CountVectorizer method\n",
    "    count_vector = CountVectorizer()\n",
    "    # Fit the training data and then return the matrix\n",
    "    training_data = count_vector.fit_transform(X_train)\n",
    "    # Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "    testing_data = count_vector.transform(X_test)\n",
    "    text_data = count_vector.transform([text])\n",
    "\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(training_data, y_train)\n",
    "    \n",
    "    return naive_bayes.predict(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d4974ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def others(text):\n",
    "    x = []\n",
    "    y_train = []\n",
    "    for i in range(4):\n",
    "    #     print(intents[\"intents\"][i])\n",
    "        label = intents[\"intents\"][i][\"tag\"]\n",
    "        for j in intents[\"intents\"][i][\"patterns\"]:\n",
    "            x.append(j)\n",
    "            y_train.append(label)\n",
    "            \n",
    "    # Instantiate the CountVectorizer method\n",
    "    count_vector = CountVectorizer()\n",
    "    # Fit the training data and then return the matrix\n",
    "    training_data = count_vector.fit_transform(x)\n",
    "    text_data = count_vector.transform([text])\n",
    "\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(training_data, y_train)\n",
    "    \n",
    "    return naive_bayes.predict(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "44c8b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(text, first, second):\n",
    "    ma = -1000000\n",
    "    sol = \"\"\n",
    "    doc = nlp(text)\n",
    "    doc = doc.similarity(text)\n",
    "    return sol\n",
    "        \n",
    "def response_others(tag):\n",
    "    for i in range(4):\n",
    "    #     print(intents[\"intents\"][i])\n",
    "        label = intents[\"intents\"][i][\"tag\"]\n",
    "        if label == tag:\n",
    "            return intents[\"intents\"][i][\"responses\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7bdbebbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'vector_norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-cfade3a41ad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfirstIntent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mget_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Buenos dias\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-160-cfade3a41ad8>\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcook_intents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcook_intents\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ingredients\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"instructions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcook_intents\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-159-ac348431dbb6>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(text, first, second)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.8/site-packages/spacy/tokens/doc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.similarity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'vector_norm'"
     ]
    }
   ],
   "source": [
    "def get_response(text):\n",
    "    firstIntent = cook_others(text)[0]\n",
    "    if firstIntent == 0:\n",
    "        intentOthers = others(text)[0]\n",
    "        return response_others(intentOthers)\n",
    "    else:\n",
    "        cook_intents = cook(text)\n",
    "        if cook_intents == 1:\n",
    "            return search(text, \"ingredients\", \"instructions\")\n",
    "\n",
    "        if cook_intents == 2:\n",
    "            return search(text, \"ingredients\", \"title\")\n",
    "\n",
    "        if cook_intents == 0:\n",
    "            return search(text, \"title\", \"instructions\")\n",
    "    return firstIntent\n",
    "\n",
    "get_response(\"Buenos dias\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
