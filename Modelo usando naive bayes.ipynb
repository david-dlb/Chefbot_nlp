{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6215c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import json\n",
    "import spacy as sp\n",
    "\n",
    "nlp = sp.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b06b957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the Intents.....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Que hacer con 1 1/2 tazas de Oporto leonado, 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Quiero Tarta de queso de higos confitados, ave...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Como preparar Posole de pavo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Si tengo 1/4 de taza de yogur natural de leche...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Como preparar Tarta de nueces a la antigua usa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>6571</td>\n",
       "      <td>游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>6572</td>\n",
       "      <td>Muchos besos no puedo darlos pero si decirlo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>6573</td>\n",
       "      <td>Gracias mi amorrrr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>6574</td>\n",
       "      <td>Te quiero millones</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>6575</td>\n",
       "      <td>Yo tambi칠n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6576 rows 칑 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  label\n",
       "0              0  Que hacer con 1 1/2 tazas de Oporto leonado, 1...      1\n",
       "1              1  Quiero Tarta de queso de higos confitados, ave...      1\n",
       "2              2                      Como preparar Posole de pavo       1\n",
       "3              3  Si tengo 1/4 de taza de yogur natural de leche...      1\n",
       "4              4  Como preparar Tarta de nueces a la antigua usa...      1\n",
       "...          ...                                                ...    ...\n",
       "6571        6571   游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢游땢...      0\n",
       "6572        6572       Muchos besos no puedo darlos pero si decirlo      0\n",
       "6573        6573                                 Gracias mi amorrrr      0\n",
       "6574        6574                                 Te quiero millones      0\n",
       "6575        6575                                         Yo tambi칠n      0\n",
       "\n",
       "[6576 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"Data/train-esp.json\")\n",
    "df_cook = pd.read_csv(\"Data/intents_cook.csv\")\n",
    "df_cook_others = pd.read_csv('Data/intents_cook_others.csv')\n",
    "\n",
    "print(\"Processing the Intents.....\")\n",
    "with open('Data/intents.json') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "df_cook_others[\"label\"] = df_cook_others.label.map({ 'cook': 1, 'others': 0})\n",
    "df_cook[\"label\"] = df_cook.label.map({ 'title': 2, 'instructions': 1, 'title_instructions': 0})\n",
    "df_cook_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbd1a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/bin/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casa</th>\n",
       "      <th>como</th>\n",
       "      <th>dinero</th>\n",
       "      <th>est치s</th>\n",
       "      <th>gana</th>\n",
       "      <th>hola</th>\n",
       "      <th>la</th>\n",
       "      <th>ll치mame</th>\n",
       "      <th>ma침ana</th>\n",
       "      <th>por</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   casa  como  dinero  est치s  gana  hola  la  ll치mame  ma침ana  por\n",
       "0     0     1       0      1     0     1   0        0       0    0\n",
       "1     1     0       1      0     2     0   1        0       0    1\n",
       "2     0     0       0      0     0     0   0        1       0    0\n",
       "3     0     0       0      0     0     1   0        1       1    0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir los documentos\n",
    "documents = ['hola, como est치s!',\n",
    "                'Gana dinero, gana por la casa.',\n",
    "                'Ll치mame.',\n",
    "                'Hola, Ll치mame ma침ana?']\n",
    "# Importar el contador de vectorizacion e inicializarlo\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "# Visualizar del objeto'count_vector' que es una instancia de 'CountVectorizer()'\n",
    "count_vector.fit(documents)\n",
    "names = count_vector.get_feature_names()\n",
    "\n",
    "doc_array = count_vector.transform(documents).toarray()\n",
    "doc_array\n",
    "\n",
    "frequency_matrix = pd.DataFrame(data=doc_array, columns=names)\n",
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df4bc0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 6576\n",
      "Number of rows in the training set: 4932\n",
      "Number of rows in the test set: 1644\n"
     ]
    }
   ],
   "source": [
    "# Dividir el conjunto de datos de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_cook_varios['text'], df_cook_varios['label'], random_state=1)\n",
    "print('Number of rows in the total set: {}'.format(df_cook_varios.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c943d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "349395a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"郊\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"郊쬪";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd3245f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = naive_bayes.predict(testing_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f59f340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9884428223844283\n",
      "Precision score:  0.9938650306748467\n",
      "Recall score:  0.994475138121547\n",
      "F1 score:  0.9941699907947222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions)))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions)))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5c766552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cook_others(text):\n",
    "    # Dividir el conjunto de datos de entrenamiento y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_cook_others['text'], df_cook_others['label'], random_state=1)\n",
    "    \n",
    "    # Instantiate the CountVectorizer method\n",
    "    count_vector = CountVectorizer()\n",
    "    # Fit the training data and then return the matrix\n",
    "    training_data = count_vector.fit_transform(X_train)\n",
    "    # Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "    testing_data = count_vector.transform(X_test)\n",
    "    text_data = count_vector.transform([text])\n",
    "\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(training_data, y_train)\n",
    "    \n",
    "    return naive_bayes.predict(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "63eed934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cook(text):\n",
    "    # Dividir el conjunto de datos de entrenamiento y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_cook['text'], df_cook['label'], random_state=1)\n",
    "    \n",
    "    # Instantiate the CountVectorizer method\n",
    "    count_vector = CountVectorizer()\n",
    "    # Fit the training data and then return the matrix\n",
    "    training_data = count_vector.fit_transform(X_train)\n",
    "    # Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "    testing_data = count_vector.transform(X_test)\n",
    "    text_data = count_vector.transform([text])\n",
    "\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(training_data, y_train)\n",
    "    \n",
    "    return naive_bayes.predict(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d4974ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def others(text):\n",
    "    x = []\n",
    "    y_train = []\n",
    "    for i in range(4):\n",
    "    #     print(intents[\"intents\"][i])\n",
    "        label = intents[\"intents\"][i][\"tag\"]\n",
    "        for j in intents[\"intents\"][i][\"patterns\"]:\n",
    "            x.append(j)\n",
    "            y_train.append(label)\n",
    "            \n",
    "    # Instantiate the CountVectorizer method\n",
    "    count_vector = CountVectorizer()\n",
    "    # Fit the training data and then return the matrix\n",
    "    training_data = count_vector.fit_transform(x)\n",
    "    text_data = count_vector.transform([text])\n",
    "\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(training_data, y_train)\n",
    "    \n",
    "    return naive_bayes.predict(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "44c8b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(text, first, second):\n",
    "    ma = -1000000\n",
    "    sol = \"\"\n",
    "    doc = nlp(text)\n",
    "    doc = doc.similarity(text)\n",
    "    return sol\n",
    "        \n",
    "def response_others(tag):\n",
    "    for i in range(4):\n",
    "    #     print(intents[\"intents\"][i])\n",
    "        label = intents[\"intents\"][i][\"tag\"]\n",
    "        if label == tag:\n",
    "            return intents[\"intents\"][i][\"responses\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7bdbebbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'vector_norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-cfade3a41ad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfirstIntent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mget_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Buenos dias\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-160-cfade3a41ad8>\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcook_intents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcook_intents\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ingredients\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"instructions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcook_intents\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-159-ac348431dbb6>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(text, first, second)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.8/site-packages/spacy/tokens/doc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.similarity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'vector_norm'"
     ]
    }
   ],
   "source": [
    "def get_response(text):\n",
    "    firstIntent = cook_others(text)[0]\n",
    "    if firstIntent == 0:\n",
    "        intentOthers = others(text)[0]\n",
    "        return response_others(intentOthers)\n",
    "    else:\n",
    "        cook_intents = cook(text)\n",
    "        if cook_intents == 1:\n",
    "            return search(text, \"ingredients\", \"instructions\")\n",
    "\n",
    "        if cook_intents == 2:\n",
    "            return search(text, \"ingredients\", \"title\")\n",
    "\n",
    "        if cook_intents == 0:\n",
    "            return search(text, \"title\", \"instructions\")\n",
    "    return firstIntent\n",
    "\n",
    "get_response(\"Buenos dias\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
